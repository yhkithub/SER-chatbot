import streamlit as st
from src.utils.initialization import initialize_session_state
from src.utils.error_handling import handle_streamlit_errors
import torch
import torchaudio
import os
from datetime import datetime
import time
from transformers import AutoModelForAudioClassification, AutoProcessor
import torchaudio.transforms as T

from src.core.services.chatbot_service import ChatbotService
from src.app.config import OpenAIConfig
from src.utils.audio_handler import process_recorded_audio, predict_audio_emotion, AudioRecorder
from src.components.message_display import apply_chat_styles, display_message, get_emotion_color
from src.core.services.personas import PERSONAS
from src.utils.state_management import (
    initialize_session_state, 
    clear_session_state, 
    ensure_state_initialization
)
from src.components.chat_components import (
    render_emotion_indicator,
    render_conversation_stats
)
from src.app.constants import (
    DEFAULT_PERSONA, 
    DEFAULT_EMOTION, 
    EMOTIONS,
    EMOTION_MAPPING,
    PERSONA_NAME_MAPPING
)

# ìŒì„± ê°ì • ì¸ì‹ ëª¨ë¸ ì„¤ì •
MODEL_NAME = "forwarder1121/ast-finetuned-model"
processor = AutoProcessor.from_pretrained(MODEL_NAME)
model = AutoModelForAudioClassification.from_pretrained(MODEL_NAME)

AUDIO_ENABLED = True
try:
    from src.utils.audio_handler import process_recorded_audio, predict_audio_emotion, AudioRecorder
except ImportError:
    AUDIO_ENABLED = False
    st.warning("Audio functionality is disabled. Please install required dependencies.")

def get_emotion_from_gpt(prompt: str) -> str:
    """
    GPTë¥¼ í†µí•´ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        prompt (str): ë¶„ì„í•  í…ìŠ¤íŠ¸
        
    Returns:
        str: ê°ì§€ëœ ê°ì • (Anger, Disgust, Fear, Happy, Neutral, Sad ì¤‘ í•˜ë‚˜)
    """
    predefined_emotions = list(EMOTION_MAPPING.values())
    emotion_prompt = (
        f"The user said: \"{prompt}\".\n"
        f"Classify the user's input into one of these emotions: {', '.join(predefined_emotions)}.\n"
        f"Respond ONLY with the emotion name (e.g., Happy, Neutral).\n"
    )

    response = st.session_state.chatbot_service.llm.invoke(emotion_prompt)
    detected_emotion = response.content.strip()

    if detected_emotion not in predefined_emotions:
        detected_emotion = DEFAULT_EMOTION

    return detected_emotion

def process_audio(waveform: torch.Tensor, target_sample_rate: int = 16000, target_length: int = 16000) -> torch.Tensor:
    """Process audio to correct format."""
    try:
        if waveform.shape[0] > 1:  # ë‹¤ì±„ë„ ì˜¤ë””ì˜¤ì¸ ê²½ìš° í‰ê·  ì²˜ë¦¬
            waveform = torch.mean(waveform, dim=0, keepdim=True)

        if waveform.shape[1] > 0:
            current_sample_rate = target_sample_rate
            if current_sample_rate != target_sample_rate:
                resampler = T.Resample(orig_freq=current_sample_rate, new_freq=target_sample_rate)
                waveform = resampler(waveform)

        if waveform.shape[1] < target_length:
            padding_length = target_length - waveform.shape[1]
            waveform = torch.nn.functional.pad(waveform, (0, padding_length))
        else:
            start = (waveform.shape[1] - target_length) // 2
            waveform = waveform[:, start:start + target_length]

        return waveform
    except Exception as e:
        st.error(f"Error in audio processing: {str(e)}")
        return None

def predict_audio_emotion(audio_path: str) -> str:
    """Predict emotion from audio file."""
    try:
        waveform, sample_rate = torchaudio.load(audio_path)
        processed_waveform = process_audio(waveform)
        if processed_waveform is None:
            return None

        inputs = processor(processed_waveform.squeeze(), sampling_rate=16000, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)

        predicted_class_idx = outputs.logits.argmax(-1).item()
        return EMOTION_MAPPING.get(predicted_class_idx, DEFAULT_EMOTION)

    except Exception as e:
        st.error(f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def handle_chat_message(prompt: str, current_persona: str) -> tuple:
    """
    ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # ê°ì • ë¶„ì„
    user_emotion = get_emotion_from_gpt(prompt)
    st.session_state.current_emotion = user_emotion
    
    # GPT ì‘ë‹µ ìƒì„±
    response = st.session_state.chatbot_service.get_response(prompt, current_persona)
    
    return user_emotion, response

def add_chat_message(role: str, content: str, emotion: str = None):
    """
    ì±„íŒ… ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    current_time = datetime.now().strftime('%p %I:%M')
    message = {
        "role": role,
        "content": content,
        "timestamp": current_time
    }
    if emotion:
        message["emotion"] = emotion
    
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    st.session_state.messages.append(message)

def update_conversation_stats(emotion: str):
    """
    ëŒ€í™” í†µê³„ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    
    Args:
        emotion (str): ê°ì§€ëœ ê°ì •
    """
    if 'conversation_stats' not in st.session_state:
        st.session_state.conversation_stats = {
            'total': 0,
            'positive': 0,
            'negative': 0
        }
    
    # ì „ì²´ ëŒ€í™” ìˆ˜ ì¦ê°€
    st.session_state.conversation_stats['total'] += 1
    
    # ê°ì •ì— ë”°ë¥¸ í†µê³„ ì—…ë°ì´íŠ¸
    positive_emotions = ['Happy']
    negative_emotions = ['Anger', 'Disgust', 'Fear', 'Sad']
    
    if emotion in positive_emotions:
        st.session_state.conversation_stats['positive'] += 1
    elif emotion in negative_emotions:
        st.session_state.conversation_stats['negative'] += 1

def render_chat_area():
    """ì±„íŒ… ì˜ì—­ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.title("ì±„íŒ…")

    # ì„¸ì…˜ ìƒíƒœ í™•ì¸
    if not st.session_state.get('initialized') or 'selected_persona' not in st.session_state:
        return

    # ë©”ì‹œì§€ í‘œì‹œ
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    # ìŠ¤íƒ€ì¼ ì ìš©
    apply_chat_styles()
    
    # ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ
    messages_container = st.container()
    with messages_container:
        for message in st.session_state.messages:
            display_message(message, persona=st.session_state.selected_persona)

    # ì±„íŒ… ì…ë ¥ ì²˜ë¦¬
    col1, col2, col3 = st.columns([8, 1.2, 1.2])
    
    with col1:
        chat_input = st.text_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", key="chat_input", label_visibility="collapsed")
    
    with col2:
        if AUDIO_ENABLED:
            # ë…¹ìŒ ìƒíƒœ ì´ˆê¸°í™”
            if 'is_recording' not in st.session_state:
                st.session_state.is_recording = False
                
            # ë§ˆì´í¬ ë²„íŠ¼
            mic_clicked = st.button(
                "âºï¸ ë…¹ìŒ ì¤‘ì§€" if st.session_state.is_recording else "ğŸ¤ ìŒì„± ì…ë ¥",
                help="í´ë¦­í•˜ì—¬ ë…¹ìŒ ì‹œì‘/ì¤‘ì§€",
                key="mic_button"
            )
            
            if mic_clicked:
                if not st.session_state.is_recording:
                    # ë…¹ìŒ ì‹œì‘
                    st.session_state.is_recording = True
                    st.session_state.audio_recorder = AudioRecorder()
                    st.session_state.audio_recorder.start_recording()
                    st.rerun()
                else:
                    # ë…¹ìŒ ì¤‘ì§€ ë° ì²˜ë¦¬
                    st.session_state.is_recording = False
                    audio_text, audio_emotion = process_recorded_audio()
                    
                    if audio_text:
                        # í˜„ì¬ ìƒíƒœ ì €ì¥
                        current_persona = st.session_state.selected_persona
                        
                        # GPT ì‘ë‹µ ìƒì„±
                        response = st.session_state.chatbot_service.get_response(audio_text, current_persona)
                        
                        # ëŒ€í™” í†µê³„ ì—…ë°ì´íŠ¸
                        update_conversation_stats(audio_emotion)
                        
                        # ë©”ì‹œì§€ ì¶”ê°€
                        add_chat_message("user", f"[ìŒì„±] {audio_text}", audio_emotion)
                        add_chat_message("assistant", response)
                        
                        # ìƒíƒœ ì—…ë°ì´íŠ¸
                        st.session_state.current_emotion = audio_emotion
                        st.session_state.last_message = audio_text
                        st.rerun()
                    else:
                        st.error("ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                        st.session_state.is_recording = False
                        st.rerun()
        else:
            # ì˜¤ë””ì˜¤ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° ë²„íŠ¼ì„ ë¹„í™œì„±í™” ìƒíƒœë¡œ í‘œì‹œ
            st.button("ğŸ¤ ìŒì„± ì…ë ¥", disabled=True, help="ìŒì„± ì…ë ¥ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    with col3:
        send_clicked = st.button("ì „ì†¡", use_container_width=True)
    
    # ìƒˆ ë©”ì‹œì§€ê°€ ìˆê³  ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ë‹¤ë©´
    if (send_clicked or chat_input) and chat_input.strip() and chat_input != st.session_state.get('last_message'):
        try:
            # í˜„ì¬ ìƒíƒœ ì €ì¥
            current_persona = st.session_state.selected_persona
            
            # ì±—ë´‡ ì„œë¹„ìŠ¤ í™•ì¸
            if 'chatbot_service' not in st.session_state:
                initialize_session_state(current_persona)
            
            # ë©”ì‹œì§€ ì²˜ë¦¬
            user_emotion, response = handle_chat_message(chat_input, current_persona)
            
            # ëŒ€í™” í†µê³„ ì—…ë°ì´íŠ¸
            update_conversation_stats(user_emotion)
            
            # ë©”ì‹œì§€ ì¶”ê°€
            add_chat_message("user", chat_input, user_emotion)
            add_chat_message("assistant", response)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.messages = st.session_state.messages
            st.session_state.current_emotion = user_emotion
            st.session_state.last_message = chat_input
            
            # í™”ë©´ ê°±ì‹ ì„ ìœ„í•œ í”Œë˜ê·¸ ì„¤ì •
            st.session_state.needs_rerun = True
            
        except Exception as e:
            st.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    # í™”ë©´ ê°±ì‹ ì´ í•„ìš”í•œ ê²½ìš°
    if st.session_state.get('needs_rerun', False):
        st.session_state.needs_rerun = False
        time.sleep(0.1)  # ì•½ê°„ì˜ ì§€ì—°ì„ ì¶”ê°€í•˜ì—¬ ìƒíƒœ ì—…ë°ì´íŠ¸ ë³´ì¥
        st.rerun()

def render_chat_page():
    """ì±„íŒ… í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    # URLì—ì„œ ì˜ì–´ í˜ë¥´ì†Œë‚˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    persona_url = st.query_params.get("persona")
    
    # í˜ë¥´ì†Œë‚˜ê°€ ì—†ìœ¼ë©´ í™ˆìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
    if not persona_url:
        st.query_params["page"] = "home"
        st.rerun()
        return
    
    # URLì˜ ì˜ì–´ ì´ë¦„ì„ í•œê¸€ í˜ë¥´ì†Œë‚˜ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
    selected_persona = PERSONA_NAME_MAPPING.get(persona_url, DEFAULT_PERSONA)
    
    # í˜ë¥´ì†Œë‚˜ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ìƒíƒœ ì´ˆê¸°í™”
    if (not st.session_state.get('initialized') or 
        st.session_state.get('selected_persona') != selected_persona):
        # ì±„íŒ… ê¸°ë¡ ìœ ì§€ë¥¼ ìœ„í•œ ì„ì‹œ ì €ì¥
        old_messages = st.session_state.get('messages', [])
        
        # ìƒíƒœ ì´ˆê¸°í™”
        clear_session_state()
        
        # ìƒˆë¡œìš´ í˜ë¥´ì†Œë‚˜ë¡œ ì´ˆê¸°í™”
        initialize_session_state(selected_persona)
        
        # ì´ì „ ì±„íŒ… ê¸°ë¡ ë³µì› (í•„ìš”í•œ ê²½ìš°)
        if old_messages and st.session_state.get('selected_persona') == selected_persona:
            st.session_state.messages = old_messages
    
    # URL íŒŒë¼ë¯¸í„° ì„¤ì •
    st.query_params["page"] = "chat"
    st.query_params["persona"] = persona_url
    
    render_sidebar()
    render_chat_area()

def render_sidebar():
    """ì‚¬ì´ë“œë°”ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    with st.sidebar:
        st.title("ê°ì •ì¸ì‹ ì±—ë´‡ ğŸ ")
        
        # í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸° ë²„íŠ¼
        if st.button("â† ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ ì„ íƒí•˜ê¸°", key="change_persona_button"):
            # ì„¸ì…˜ ìƒíƒœ ì™„ì „ ì´ˆê¸°í™”
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            
            # URL íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”
            for param in list(st.query_params.keys()):
                del st.query_params[param]
            
            # í™ˆ í˜ì´ì§€ë¡œ ì´ë™í•˜ê¸° ìœ„í•œ íŒŒë¼ë¯¸í„° ì„¤ì •
            st.query_params["page"] = "home"
            st.rerun()
            return

        st.markdown("### ì‚¬ìš© ë°©ë²•")
        st.markdown("""
        1. ì±„íŒ…ì°½ì— í˜„ì¬ ê¸°ë¶„ì´ë‚˜ ìƒí™©ì„ ì…ë ¥í•˜ì„¸ìš”.
        2. ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìŒì„±ìœ¼ë¡œ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        3. ì±—ë´‡ì´ ê°ì •ì„ ë¶„ì„í•˜ê³  ê³µê°ì ì¸ ëŒ€í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        4. í•„ìš”í•œ ê²½ìš° ì ì ˆí•œ ì¡°ì–¸ì´ë‚˜ ìœ„ë¡œë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """)

        # í˜„ì¬ í˜ë¥´ì†Œë‚˜ í‘œì‹œ
        current_persona = st.session_state.get('selected_persona', st.query_params.get("persona"))
        st.markdown(f"### í˜„ì¬ ëŒ€ ìƒëŒ€: {current_persona}")

        # ìƒíƒœ ì´ˆê¸°í™” ë° í‘œì‹œ
        ensure_state_initialization('current_emotion', DEFAULT_EMOTION)
        ensure_state_initialization('conversation_stats', {'total': 0, 'positive': 0, 'negative': 0})
        render_emotion_indicator(st.session_state.current_emotion)
        render_conversation_stats(st.session_state.conversation_stats)

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="ê°ì •ì¸ì‹ ì±—ë´‡",
        page_icon="ğŸ¤—",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # í˜ì¬ í˜ì´ì§€ í™•ì¸
    current_page = st.query_params.get("page", "home")
    
    # í˜ì´ì§€ ë¼ìš°íŒ…
    if current_page == "chat":
        render_chat_page()
    else:
        from src.app.home import render_home
        render_home()

if __name__ == "__main__":
    main()
